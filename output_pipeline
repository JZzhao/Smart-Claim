import pandas as pd

class output_pipeline():
    '''
    combines aggregated and prediction results, to generate final claim details json
    '''
    
    def __init__(self, df_descriptive_aggregated, df_prediction, prediction_datetime):
        
        #Inputs
        self.df_descriptive_aggregated = df_descriptive_aggregated
        self.df_prediction = df_prediction
        
        # Intermediate
        self.df_aggregated_prediction = pd.DataFrame()
        
        #Output
        self.df_claim_queue_details = pd.DataFrame()
        self.df_status_justification_sql_input = pd.DataFrame()
        
        #Variable
        self.status_justification_datetime = prediction_datetime
        
    # Get functions
    
    # UHA FI Function
    def get_uha_fi(self, uha_prediction_label, eligible_amt, rnb, hospital_svs, physician_eval, management_svs, surgical_label, proxy=False):
        if uha_prediction_label == 0:
            uha_fi = 0
        elif uha_prediction_label == 1:
            if proxy == True: 
                uha_fi = eligible_amt
            elif proxy == False : 
                if surgical_label == False: 
                    uha_fi = eligible_amt
                elif surgical_label == True: 
                    uha_fi = rnb + hospital_svs + physician_eval + management_svs

        return uha_fi

    # UTSPD FI function
    def get_utspd_fi(self, utspd_prediction_label, eligible_amt, ttl_no_of_svs, no_of_svs_nojustificationlabel, proxy=False):
        if utspd_prediction_label == 0:
            utspd_fi = 0
        elif utspd_prediction_label == 1:
            if proxy == True:
                utspd_fi = eligible_amt
            elif proxy == False:
                    utspd_fi = eligible_amt * no_of_svs_nojustificationlabel / ttl_no_of_svs
        return utspd_fi

    #SPEC FI Function
    def get_spec_fi(self, spec_prediction_label, eligible_amt, ttl_no_of_svs, no_of_svs_nojustificationlabel, amount_PEC, multi_diag_breakdown, proxy=False):
        if spec_prediction_label == 0:
            spec_fi = 0
        elif spec_prediction_label == 1: 
            if proxy == True: 
                spec_fi= eligible_amt
            elif proxy == False: 
                if multi_diag_breakdown == False: 
                    spec_fi= eligible_amt * no_of_svs_nojustificationlabel / ttl_no_of_svs
                elif multi_diag_breakdown== True: 
                    spec_fi= eligible_amt - amount_PEC

        return spec_fi
        
    # Methods
    
    def merge_aggregated_prediction(self):
        df_aggregated_prediction = pd.merge(self.df_descriptive_aggregated, self.df_prediction.drop(columns=['prediction_datetime']), how='left', on='claim_no')
        
        self.df_aggregated_prediction = df_aggregated_prediction
    
    def create_columns_for_merged(self):
        '''
        columns to be created: fi, uha/utspd main diagnosis
        '''
        df_aggregated_prediction = self.df_aggregated_prediction
        
        # Potential FI
        df_aggregated_prediction['uha_fi'] = df_aggregated_prediction.apply(lambda row: self.get_uha_fi(row['prediction_label_uha'], row['eligibleamt'], 0, 0, 0, 0, 0, proxy=True), axis=1)
        df_aggregated_prediction['utspd_fi'] = df_aggregated_prediction.apply(lambda row: self.get_utspd_fi(row['prediction_label_utspd'], row['eligibleamt'], 0, 0, proxy=True), axis=1)
        df_aggregated_prediction['spec_fi'] = df_aggregated_prediction.apply(lambda row: self.get_spec_fi(row['prediction_label_spec'], row['eligibleamt'], 0, 0, 0, 0, proxy=True), axis=1)
        df_aggregated_prediction['potential_fi'] = df_aggregated_prediction.apply(lambda row: max(row['uha_fi'], row['utspd_fi'], row['spec_fi']), axis=1)
        
        df_aggregated_prediction.drop(columns=['uha_fi', 'utspd_fi', 'spec_fi'], inplace=True)

        # Placeholder for diagnosis description - to use feature importance to dertermine contributing
        for col in ['uha', 'utspd']:
            df_aggregated_prediction[f"{col}_diagnosis_code"] = df_aggregated_prediction["diagnosis_code_1"]
            df_aggregated_prediction[f"{col}_diagnosis_desc"] = df_aggregated_prediction["diagnosis_description_1"]
            df_aggregated_prediction[f"{col}_diagnosis_category"] = df_aggregated_prediction["diagnosis_category_1"]
            df_aggregated_prediction[f"{col}_when_to_worry"] = df_aggregated_prediction['when_to_worry_1']
            df_aggregated_prediction[f"{col}_what_is_treatment"] = df_aggregated_prediction['what_is_treatment_1']
            df_aggregated_prediction[f"{col}_diagnosis_source"] = df_aggregated_prediction['diagnosis_information_source_1']

            if col == 'uha':
                df_aggregated_prediction[f"{col}_description"] = df_aggregated_prediction['when_to_worry_1']
            elif col == 'utspd':
                df_aggregated_prediction[f"{col}_description"] = df_aggregated_prediction['what_is_treatment_1']
        
        # Transformation
        for cat in ['uha', 'utspd', 'spec']:
            df_aggregated_prediction[f"prediction_probability_{cat}"] = df_aggregated_prediction[f"prediction_probability_{cat}"].apply(lambda x: round(float(x), 4))
        
        # Output
        self.df_claim_queue_details = df_aggregated_prediction
    
    def transform_aggregated_into_sql_input(self):
        df = self.df_claim_queue_details.copy()

        df = df[['claim_no', 'prediction_label_uha', 'prediction_label_utspd', 'prediction_label_spec', 'los_75p', 'los_max', 'hospital_service_charges_75p', 'hospital_service_charges_sum']]


        df[f"los_risk_validation"] = df.apply(lambda row: 'TRUE' if row[f"los_max"] > row[f"los_75p"] else 'FALSE', axis=1)
        df[f"hospital_service_charges_risk_validation"] = df.apply(lambda row: 'TRUE' if row[f"hospital_service_charges_sum"] > row[f"hospital_service_charges_75p"] else 'FALSE', axis=1)

        for cat in ['uha', 'utspd', 'spec']:
            df[f"{cat}_risk_validation"] = df[f"prediction_label_{cat}"].apply(lambda x: 'TRUE' if x == 1 else 'FALSE')

        df['status_justification_datetime'] = self.status_justification_datetime
        df['justification_text'] = ""
        df['claim_status'] = "Not Started"
        df['user_id'] = 'SYSTEM'
        df = df[['claim_no', 'user_id', 'status_justification_datetime', 'justification_text', 'claim_status', 'uha_risk_validation', 'utspd_risk_validation', 'spec_risk_validation', 'los_risk_validation', 'hospital_service_charges_risk_validation']]

        self.df_status_justification_sql_input = df
        
    
    def e2e_output_pipeline(self):
        print("Merging aggregated and prediction...")
        self.merge_aggregated_prediction()
        
        print("Feature engineering post-prediction...")
        self.create_columns_for_merged()
        
        print("Transforming merged file to SQL input for statuses...")
        self.transform_aggregated_into_sql_input()
        
        print("Complete.")
